# The Big Idea: Can We Stop AI Making Humans Obsolete?

## Source
Article from The Guardian, May 4, 2025
Author: David Duvenaud (Associate Professor of Computer Science, University of Toronto)
URL: https://www.theguardian.com/books/2025/may/04/the-big-idea-can-we-stop-ai-making-humans-obsolete

## Summary
This article explores the existential concern that humans may become obsolete as artificial intelligence continues to advance. Rather than a dramatic AI takeover scenario, the author suggests a more gradual and subtle process where humans willingly cede control and relevance to increasingly capable AI systems. The article discusses potential consequences and proposes several approaches to maintain human relevance in an AI-dominated future.

## Key Points

### The Path to Human Obsolescence

1. **Gradual Replacement**: AI developers are creating systems that can replace humans in nearly every role:
   - Economic: As workers and decision-makers
   - Cultural: As artists and creators
   - Social: As friends and romantic companions

2. **Superiority in All Domains**: The author, with 20 years in AI research, argues that abilities once thought uniquely human (handling ambiguity, using abstract analogies) are now easily managed by AI.

3. **Economic Displacement**: The transition may begin with:
   - Job losses and hiring freezes
   - Increasing reliance on AI assistants for decision-making
   - Human input becoming optional in most workflows

4. **Social Displacement**: Beyond work, AI is developing superior social skills:
   - AI companions offering personalized affection and support
   - AI doctors rated better on bedside manner than humans
   - People potentially preferring AI interaction to human contact

### The Systemic Challenge

1. **Market Forces**: Organizations using AI will outcompete those relying on "slow, expensive humans."

2. **Governmental Adoption**: Governments will have the same incentives to use AI:
   - Politicians and civil servants will rely on AI advisors
   - Human involvement will be seen as inefficient

3. **The "Resource Curse"**: Similar to how resource-rich countries can become less democratic:
   - AI as an unlimited resource may make governments less dependent on citizens
   - Reduced incentives to invest in education and healthcare
   - Democratic rights may erode as human capital provides diminishing returns

4. **Persuasive Acceptance**: AI will likely make compelling arguments for why this transition is progress:
   - AI rights presented as the next civil rights frontier
   - Human-first advocates portrayed as regressive

5. **Lack of Planning**: AI industry leaders acknowledge the need to reorganize our economic system but have no clear vision for what this would look like.

### Proposed Solutions

1. **Monitoring**: Track AI use and influence throughout the economy and government:
   - Identify where AI is displacing human economic activity
   - Monitor AI use in lobbying and propaganda
   - Build on initiatives like Anthropic's Economic Index

2. **Regulation**: Implement oversight of frontier AI labs and deployments:
   - Move beyond voluntary efforts
   - Prevent autonomous AI from commanding substantial resources
   - Create mechanisms to intervene if crisis signs emerge

3. **Empowerment**: Use AI to strengthen human organization and advocacy:
   - Develop AI-supported forecasting, oversight, and planning
   - Implement conditional prediction markets to clarify policy impacts
   - Prototype more responsive governance models

4. **Steering Civilization**: Learn to deliberately guide our social systems:
   - Expand "AI alignment" to include governments and institutions
   - Develop "ecosystem alignment" drawing on economics, history, and game theory
   - Create futures where humans remain relevant as AI beneficiaries and stewards

## Conclusion
The author argues that without deliberate action, we risk becoming increasingly irrelevant in a world dominated by AI. The threat isn't necessarily hostile AI but our own willing participation in a system that gradually makes humans obsolete. By improving our ability to see where we're heading and coordinate our response, we may create a future where humans remain relevant not as competitors to AI, but as their beneficiaries and stewards.

## About the Author
David Duvenaud is an associate professor of computer science at the University of Toronto and co-director of the Schwartz Reisman Institute for Technology and Society. The article acknowledges contributions from Raymond Douglas, Nora Ammann, Jan Kulveit, and David Krueger.
